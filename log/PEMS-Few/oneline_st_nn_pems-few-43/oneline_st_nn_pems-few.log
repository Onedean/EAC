2024-09-29 23:29:46,422 - logger name:log/PEMS-Few/oneline_st_nn_pems-few-43/oneline_st_nn_pems-few.log
2024-09-29 23:29:46,423 - params : {'conf': 'new_conf/PEMS-Few/oneline_st_nn_pems-few.json', 'seed': 43, 'paral': 0, 'gpuid': 2, 'logname': 'oneline_st_nn_pems-few', 'method': 'TrafficStream', 'load_first_year': 0, 'first_year_model_path': 'log/PEMS/trafficstream-42/2011/16.6936.pkl', 'device': device(type='cuda', index=2), 'methods': {'TrafficStream': <class 'src.model.model.TrafficStream_Model'>, 'STKEC': <class 'src.model.model.STKEC_Model'>, 'EAC': <class 'src.model.model.EAC_Model'>}, 'begin_year': 2011, 'end_year': 2017, 'dropout': 0.0, 'lr': 0.01, 'batch_size': 128, 'epoch': 100, 'loss': 'mse', 'activation': 'relu', 'scheduler': 'epo', 'y_len': 12, 'x_len': 12, 'data_process': 0, 'raw_data_path': 'data/PEMS-Few/RawData/', 'save_data_path': 'data/PEMS-Few/FastData/', 'graph_path': 'data/PEMS-Few/graph/', 'model_path': 'log/PEMS-Few/', 'gcn': {'in_channel': 12, 'out_channel': 12, 'hidden_channel': 64}, 'tcn': {'in_channel': 1, 'out_channel': 1, 'kernel_size': 3, 'dilation': 1}, 'init': True, 'train': 1, 'auto_test': 0, 'strategy': 'incremental', 'increase': True, 'num_hops': 2, 'detect': False, 'ewc': False, 'replay': False, 'path': 'log/PEMS-Few/oneline_st_nn_pems-few-43', 'logger': <Logger utils.initialize (INFO)>}
2024-09-29 23:29:46,440 - [*] Year 2011 load from data/PEMS-Few/FastData/2011.npz
2024-09-29 23:29:47,985 - [*] Year 2011 Dataset load!
2024-09-29 23:29:47,989 - Total Parameters: 3308
2024-09-29 23:29:47,989 - Trainable Parameters: 3308
2024-09-29 23:29:47,989 - [*] Year 2011 Training start
2024-09-29 23:29:50,261 - node number torch.Size([83840, 12])
2024-09-29 23:29:58,218 - epoch:0, training loss:34482.6055 validation loss:129.5418
2024-09-29 23:30:05,880 - epoch:1, training loss:24893.8651 validation loss:82.5654
2024-09-29 23:30:13,113 - epoch:2, training loss:7767.9567 validation loss:48.4417
2024-09-29 23:30:19,591 - epoch:3, training loss:4268.2365 validation loss:37.2984
2024-09-29 23:30:26,252 - epoch:4, training loss:2468.9103 validation loss:25.7240
2024-09-29 23:30:32,813 - epoch:5, training loss:1737.0398 validation loss:25.1503
2024-09-29 23:30:40,184 - epoch:6, training loss:1565.2489 validation loss:24.1022
2024-09-29 23:30:47,948 - epoch:7, training loss:1476.3279 validation loss:22.6587
2024-09-29 23:30:55,635 - epoch:8, training loss:1376.2757 validation loss:21.9814
2024-09-29 23:31:03,024 - epoch:9, training loss:1278.6326 validation loss:21.2316
2024-09-29 23:31:10,016 - epoch:10, training loss:1173.7143 validation loss:19.9692
2024-09-29 23:31:16,756 - epoch:11, training loss:1064.7323 validation loss:19.4715
2024-09-29 23:31:23,823 - epoch:12, training loss:974.1303 validation loss:18.8934
2024-09-29 23:31:31,116 - epoch:13, training loss:913.1090 validation loss:18.5769
2024-09-29 23:31:38,363 - epoch:14, training loss:873.3012 validation loss:18.3970
2024-09-29 23:31:45,627 - epoch:15, training loss:839.4931 validation loss:18.1314
2024-09-29 23:31:53,046 - epoch:16, training loss:818.6981 validation loss:17.9859
2024-09-29 23:32:00,382 - epoch:17, training loss:803.2087 validation loss:18.0311
2024-09-29 23:32:07,700 - epoch:18, training loss:797.1872 validation loss:17.7846
2024-09-29 23:32:14,864 - epoch:19, training loss:786.5305 validation loss:17.7756
2024-09-29 23:32:21,985 - epoch:20, training loss:779.8856 validation loss:17.5228
2024-09-29 23:32:29,335 - epoch:21, training loss:771.4444 validation loss:17.7539
2024-09-29 23:32:36,571 - epoch:22, training loss:763.0937 validation loss:17.5140
2024-09-29 23:32:43,767 - epoch:23, training loss:755.9670 validation loss:17.6518
2024-09-29 23:32:50,914 - epoch:24, training loss:755.2953 validation loss:17.2044
2024-09-29 23:32:57,990 - epoch:25, training loss:748.3752 validation loss:17.1282
2024-09-29 23:33:05,160 - epoch:26, training loss:747.2500 validation loss:17.1390
2024-09-29 23:33:12,245 - epoch:27, training loss:737.6139 validation loss:17.2692
2024-09-29 23:33:19,349 - epoch:28, training loss:740.4667 validation loss:17.2966
2024-09-29 23:33:26,582 - epoch:29, training loss:733.8844 validation loss:17.0934
2024-09-29 23:33:33,614 - epoch:30, training loss:740.5933 validation loss:17.5360
2024-09-29 23:33:40,735 - epoch:31, training loss:734.8948 validation loss:17.3650
2024-09-29 23:33:46,825 - epoch:32, training loss:725.1292 validation loss:17.3732
2024-09-29 23:33:53,414 - epoch:33, training loss:726.3740 validation loss:17.2096
2024-09-29 23:33:58,876 - epoch:34, training loss:723.2514 validation loss:16.7943
2024-09-29 23:34:06,256 - epoch:35, training loss:737.1110 validation loss:17.1087
2024-09-29 23:34:13,410 - epoch:36, training loss:722.9910 validation loss:17.1880
2024-09-29 23:34:20,263 - epoch:37, training loss:726.1697 validation loss:17.4584
2024-09-29 23:34:27,035 - epoch:38, training loss:718.0896 validation loss:16.9830
2024-09-29 23:34:34,060 - epoch:39, training loss:710.5582 validation loss:16.7706
2024-09-29 23:34:40,396 - epoch:40, training loss:714.0358 validation loss:16.7624
2024-09-29 23:34:46,699 - epoch:41, training loss:710.6296 validation loss:16.9268
2024-09-29 23:34:53,292 - epoch:42, training loss:704.5578 validation loss:16.6166
2024-09-29 23:35:00,152 - epoch:43, training loss:703.5793 validation loss:16.6784
2024-09-29 23:35:10,012 - epoch:44, training loss:700.2018 validation loss:16.6050
2024-09-29 23:35:19,653 - epoch:45, training loss:696.4123 validation loss:17.0661
2024-09-29 23:35:27,353 - epoch:46, training loss:702.0991 validation loss:17.1876
2024-09-29 23:35:33,871 - epoch:47, training loss:695.0891 validation loss:16.7073
2024-09-29 23:35:43,512 - epoch:48, training loss:699.7633 validation loss:16.6803
2024-09-29 23:35:53,456 - epoch:49, training loss:717.0427 validation loss:17.3946
2024-09-29 23:36:03,260 - epoch:50, training loss:717.3157 validation loss:17.0802
2024-09-29 23:36:08,549 - [*] loss:643.9222
2024-09-29 23:36:08,576 - [*] year 2011, testing
2024-09-29 23:36:08,878 - T:3	MAE	13.5137	RMSE	20.5489	MAPE	17.6148
2024-09-29 23:36:09,497 - T:6	MAE	14.4555	RMSE	22.2173	MAPE	18.7131
2024-09-29 23:36:11,390 - T:12	MAE	16.4745	RMSE	25.5922	MAPE	21.2981
2024-09-29 23:36:11,390 - T:Avg	MAE	14.6277	RMSE	22.4623	MAPE	18.9803
2024-09-29 23:36:11,392 - Finished optimization, total time:296.20 s, best model:log/PEMS-Few/oneline_st_nn_pems-few-43/2011/16.605.pkl
2024-09-29 23:36:11,410 - [*] Year 2012 load from data/PEMS-Few/FastData/2012.npz
2024-09-29 23:36:11,419 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2011/129.5418.pkl
2024-09-29 23:36:12,132 - number of increase nodes:59, nodes after 2 hop:torch.Size([182]), total nodes this year 715
2024-09-29 23:36:12,700 - [*] Year 2012 Dataset load!
2024-09-29 23:36:12,700 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2011/129.5418.pkl
2024-09-29 23:36:13,115 - Total Parameters: 3308
2024-09-29 23:36:13,115 - Trainable Parameters: 3308
2024-09-29 23:36:13,116 - [*] Year 2012 Training start
2024-09-29 23:36:14,143 - node number torch.Size([23296, 12])
2024-09-29 23:36:24,879 - epoch:0, training loss:26305.5739 validation loss:91.0865
2024-09-29 23:36:37,943 - epoch:1, training loss:10024.4177 validation loss:60.8536
2024-09-29 23:36:51,459 - epoch:2, training loss:3831.5892 validation loss:35.7549
2024-09-29 23:37:03,153 - epoch:3, training loss:2120.4015 validation loss:26.8034
2024-09-29 23:37:14,833 - epoch:4, training loss:1571.7172 validation loss:23.2035
2024-09-29 23:37:27,178 - epoch:5, training loss:1412.7040 validation loss:23.1829
2024-09-29 23:37:40,607 - epoch:6, training loss:1347.8178 validation loss:22.5595
2024-09-29 23:37:52,847 - epoch:7, training loss:1293.4089 validation loss:22.0344
2024-09-29 23:38:05,839 - epoch:8, training loss:1234.5888 validation loss:21.1138
2024-09-29 23:38:19,145 - epoch:9, training loss:1168.6934 validation loss:20.4699
2024-09-29 23:38:32,675 - epoch:10, training loss:1099.2576 validation loss:19.9516
2024-09-29 23:38:44,736 - epoch:11, training loss:1020.4690 validation loss:19.4354
2024-09-29 23:38:57,969 - epoch:12, training loss:935.4052 validation loss:18.3865
2024-09-29 23:39:10,708 - epoch:13, training loss:857.9745 validation loss:18.0513
2024-09-29 23:39:23,572 - epoch:14, training loss:806.0425 validation loss:18.0426
2024-09-29 23:39:36,887 - epoch:15, training loss:785.5508 validation loss:17.7261
2024-09-29 23:39:48,667 - epoch:16, training loss:770.2150 validation loss:17.8911
2024-09-29 23:40:00,368 - epoch:17, training loss:761.7291 validation loss:17.7017
2024-09-29 23:40:11,659 - epoch:18, training loss:751.8055 validation loss:17.4597
2024-09-29 23:40:21,961 - epoch:19, training loss:741.6842 validation loss:17.2130
2024-09-29 23:40:33,037 - epoch:20, training loss:728.2718 validation loss:17.1006
2024-09-29 23:40:44,060 - epoch:21, training loss:720.0233 validation loss:17.5084
2024-09-29 23:40:54,991 - epoch:22, training loss:709.8594 validation loss:16.4662
2024-09-29 23:41:05,191 - epoch:23, training loss:707.5479 validation loss:16.8962
2024-09-29 23:41:15,273 - epoch:24, training loss:697.4713 validation loss:17.4335
2024-09-29 23:41:24,967 - epoch:25, training loss:694.3768 validation loss:16.4754
2024-09-29 23:41:34,420 - epoch:26, training loss:692.6931 validation loss:16.5070
2024-09-29 23:41:42,955 - epoch:27, training loss:681.1655 validation loss:16.7421
2024-09-29 23:41:52,350 - epoch:28, training loss:679.0574 validation loss:16.6651
2024-09-29 23:41:56,875 - [*] loss:748.1335
2024-09-29 23:41:56,904 - [*] year 2012, testing
2024-09-29 23:41:57,214 - T:3	MAE	14.0948	RMSE	21.8781	MAPE	22.4546
2024-09-29 23:41:57,766 - T:6	MAE	14.9867	RMSE	23.5343	MAPE	23.3946
2024-09-29 23:41:59,794 - T:12	MAE	17.3312	RMSE	27.5896	MAPE	26.1809
2024-09-29 23:41:59,794 - T:Avg	MAE	15.2832	RMSE	23.9785	MAPE	23.9518
2024-09-29 23:41:59,796 - Finished optimization, total time:201.41 s, best model:log/PEMS-Few/oneline_st_nn_pems-few-43/2012/16.4662.pkl
2024-09-29 23:41:59,820 - [*] Year 2013 load from data/PEMS-Few/FastData/2013.npz
2024-09-29 23:41:59,837 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2012/16.4662.pkl
2024-09-29 23:42:00,368 - number of increase nodes:71, nodes after 2 hop:torch.Size([146]), total nodes this year 786
2024-09-29 23:42:00,938 - [*] Year 2013 Dataset load!
2024-09-29 23:42:00,938 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2012/16.4662.pkl
2024-09-29 23:42:01,337 - Total Parameters: 3308
2024-09-29 23:42:01,337 - Trainable Parameters: 3308
2024-09-29 23:42:01,337 - [*] Year 2013 Training start
2024-09-29 23:42:02,509 - node number torch.Size([18688, 12])
2024-09-29 23:42:10,042 - epoch:0, training loss:633.5745 validation loss:14.9855
2024-09-29 23:42:18,655 - epoch:1, training loss:544.4186 validation loss:14.4051
2024-09-29 23:42:26,290 - epoch:2, training loss:505.6801 validation loss:14.8321
2024-09-29 23:42:35,094 - epoch:3, training loss:498.4454 validation loss:15.2164
2024-09-29 23:42:43,320 - epoch:4, training loss:494.3518 validation loss:14.3125
2024-09-29 23:42:51,613 - epoch:5, training loss:492.0937 validation loss:15.1577
2024-09-29 23:43:00,301 - epoch:6, training loss:492.5739 validation loss:13.9545
2024-09-29 23:43:07,958 - epoch:7, training loss:483.5987 validation loss:14.4130
2024-09-29 23:43:17,291 - epoch:8, training loss:481.0227 validation loss:14.3044
2024-09-29 23:43:25,551 - epoch:9, training loss:479.3294 validation loss:14.7025
2024-09-29 23:43:34,596 - epoch:10, training loss:475.4979 validation loss:14.5494
2024-09-29 23:43:43,669 - epoch:11, training loss:473.3366 validation loss:13.8958
2024-09-29 23:43:50,367 - epoch:12, training loss:471.3962 validation loss:13.6566
2024-09-29 23:43:58,623 - epoch:13, training loss:477.6852 validation loss:13.7876
2024-09-29 23:44:07,032 - epoch:14, training loss:471.2034 validation loss:14.2969
2024-09-29 23:44:13,865 - epoch:15, training loss:466.7471 validation loss:14.7079
2024-09-29 23:44:23,179 - epoch:16, training loss:469.5649 validation loss:14.3337
2024-09-29 23:44:32,189 - epoch:17, training loss:467.4251 validation loss:13.6159
2024-09-29 23:44:41,333 - epoch:18, training loss:473.4452 validation loss:14.0608
2024-09-29 23:44:49,923 - epoch:19, training loss:463.6446 validation loss:14.1219
2024-09-29 23:44:58,020 - epoch:20, training loss:462.1474 validation loss:13.9399
2024-09-29 23:45:05,817 - epoch:21, training loss:462.0692 validation loss:14.5497
2024-09-29 23:45:13,664 - epoch:22, training loss:476.2591 validation loss:14.3343
2024-09-29 23:45:21,924 - epoch:23, training loss:486.2373 validation loss:14.8028
2024-09-29 23:45:24,856 - [*] loss:760.0058
2024-09-29 23:45:24,886 - [*] year 2013, testing
2024-09-29 23:45:25,207 - T:3	MAE	13.5268	RMSE	21.5818	MAPE	17.7175
2024-09-29 23:45:25,969 - T:6	MAE	14.5944	RMSE	23.6015	MAPE	18.7858
2024-09-29 23:45:28,083 - T:12	MAE	17.0517	RMSE	27.8023	MAPE	21.5123
2024-09-29 23:45:28,083 - T:Avg	MAE	14.8297	RMSE	23.9226	MAPE	19.0778
2024-09-29 23:45:28,084 - Finished optimization, total time:110.97 s, best model:log/PEMS-Few/oneline_st_nn_pems-few-43/2013/13.6159.pkl
2024-09-29 23:45:28,102 - [*] Year 2014 load from data/PEMS-Few/FastData/2014.npz
2024-09-29 23:45:28,110 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2013/13.6159.pkl
2024-09-29 23:45:28,640 - number of increase nodes:36, nodes after 2 hop:torch.Size([151]), total nodes this year 822
2024-09-29 23:45:29,243 - [*] Year 2014 Dataset load!
2024-09-29 23:45:29,243 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2013/13.6159.pkl
2024-09-29 23:45:29,535 - Total Parameters: 3308
2024-09-29 23:45:29,535 - Trainable Parameters: 3308
2024-09-29 23:45:29,535 - [*] Year 2014 Training start
2024-09-29 23:45:30,662 - node number torch.Size([19328, 12])
2024-09-29 23:45:36,828 - epoch:0, training loss:576.7688 validation loss:12.9729
2024-09-29 23:45:45,104 - epoch:1, training loss:523.2595 validation loss:13.0614
2024-09-29 23:45:53,687 - epoch:2, training loss:509.6382 validation loss:13.3252
2024-09-29 23:46:02,958 - epoch:3, training loss:505.6404 validation loss:12.8756
2024-09-29 23:46:11,689 - epoch:4, training loss:508.0449 validation loss:13.0806
2024-09-29 23:46:20,692 - epoch:5, training loss:505.4009 validation loss:12.7025
2024-09-29 23:46:30,121 - epoch:6, training loss:507.0903 validation loss:12.7876
2024-09-29 23:46:39,418 - epoch:7, training loss:503.2333 validation loss:12.8243
2024-09-29 23:46:48,714 - epoch:8, training loss:500.9544 validation loss:13.0509
2024-09-29 23:46:56,904 - epoch:9, training loss:501.9911 validation loss:12.9327
2024-09-29 23:47:04,458 - epoch:10, training loss:496.0901 validation loss:12.7695
2024-09-29 23:47:12,633 - epoch:11, training loss:496.6058 validation loss:13.3175
2024-09-29 23:47:16,357 - [*] loss:808.6646
2024-09-29 23:47:16,390 - [*] year 2014, testing
2024-09-29 23:47:16,718 - T:3	MAE	13.9554	RMSE	22.3118	MAPE	18.1856
2024-09-29 23:47:17,481 - T:6	MAE	15.0452	RMSE	24.3861	MAPE	19.1315
2024-09-29 23:47:20,037 - T:12	MAE	17.5387	RMSE	28.7463	MAPE	21.5562
2024-09-29 23:47:20,038 - T:Avg	MAE	15.2848	RMSE	24.7323	MAPE	19.3909
2024-09-29 23:47:20,042 - Finished optimization, total time:60.24 s, best model:log/PEMS-Few/oneline_st_nn_pems-few-43/2014/12.7025.pkl
2024-09-29 23:47:20,066 - [*] Year 2015 load from data/PEMS-Few/FastData/2015.npz
2024-09-29 23:47:20,083 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2014/12.7025.pkl
2024-09-29 23:47:20,477 - number of increase nodes:12, nodes after 2 hop:torch.Size([25]), total nodes this year 834
2024-09-29 23:47:21,054 - [*] Year 2015 Dataset load!
2024-09-29 23:47:21,054 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2014/12.7025.pkl
2024-09-29 23:47:21,272 - Total Parameters: 3308
2024-09-29 23:47:21,272 - Trainable Parameters: 3308
2024-09-29 23:47:21,273 - [*] Year 2015 Training start
2024-09-29 23:47:22,183 - node number torch.Size([3200, 12])
2024-09-29 23:47:28,106 - epoch:0, training loss:259.9089 validation loss:10.5281
2024-09-29 23:47:35,121 - epoch:1, training loss:197.9110 validation loss:11.1363
2024-09-29 23:47:41,357 - epoch:2, training loss:181.8214 validation loss:9.8559
2024-09-29 23:47:46,950 - epoch:3, training loss:178.4311 validation loss:10.4383
2024-09-29 23:47:53,305 - epoch:4, training loss:174.9161 validation loss:10.4686
2024-09-29 23:48:00,054 - epoch:5, training loss:173.5047 validation loss:9.8353
2024-09-29 23:48:06,016 - epoch:6, training loss:172.5455 validation loss:10.2921
2024-09-29 23:48:12,377 - epoch:7, training loss:172.2429 validation loss:9.9793
2024-09-29 23:48:18,784 - epoch:8, training loss:172.7038 validation loss:9.9643
2024-09-29 23:48:24,557 - epoch:9, training loss:170.1240 validation loss:10.2471
2024-09-29 23:48:29,460 - epoch:10, training loss:171.0123 validation loss:9.6945
2024-09-29 23:48:35,226 - epoch:11, training loss:169.8657 validation loss:10.1324
2024-09-29 23:48:40,958 - epoch:12, training loss:169.5899 validation loss:10.1658
2024-09-29 23:48:46,167 - epoch:13, training loss:168.4431 validation loss:10.4988
2024-09-29 23:48:51,183 - epoch:14, training loss:168.6021 validation loss:9.9978
2024-09-29 23:48:55,647 - epoch:15, training loss:166.8811 validation loss:10.4409
2024-09-29 23:49:00,423 - epoch:16, training loss:166.3049 validation loss:9.9072
2024-09-29 23:49:02,674 - [*] loss:1319.7915
2024-09-29 23:49:02,729 - [*] year 2015, testing
2024-09-29 23:49:03,140 - T:3	MAE	15.8862	RMSE	25.7074	MAPE	19.0578
2024-09-29 23:49:03,990 - T:6	MAE	17.7442	RMSE	29.1668	MAPE	20.4449
2024-09-29 23:49:06,573 - T:12	MAE	21.9097	RMSE	36.7718	MAPE	23.5455
2024-09-29 23:49:06,573 - T:Avg	MAE	18.1403	RMSE	29.8737	MAPE	20.7207
2024-09-29 23:49:06,575 - Finished optimization, total time:53.54 s, best model:log/PEMS-Few/oneline_st_nn_pems-few-43/2015/9.6945.pkl
2024-09-29 23:49:06,597 - [*] Year 2016 load from data/PEMS-Few/FastData/2016.npz
2024-09-29 23:49:06,607 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2015/10.5281.pkl
2024-09-29 23:49:06,906 - number of increase nodes:16, nodes after 2 hop:torch.Size([31]), total nodes this year 850
2024-09-29 23:49:07,438 - [*] Year 2016 Dataset load!
2024-09-29 23:49:07,438 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2015/10.5281.pkl
2024-09-29 23:49:07,595 - Total Parameters: 3308
2024-09-29 23:49:07,595 - Trainable Parameters: 3308
2024-09-29 23:49:07,595 - [*] Year 2016 Training start
2024-09-29 23:49:08,576 - node number torch.Size([3968, 12])
2024-09-29 23:49:12,078 - epoch:0, training loss:799.8668 validation loss:14.7738
2024-09-29 23:49:16,272 - epoch:1, training loss:718.0175 validation loss:14.4480
2024-09-29 23:49:20,360 - epoch:2, training loss:698.1636 validation loss:14.3126
2024-09-29 23:49:24,194 - epoch:3, training loss:688.6740 validation loss:14.5332
2024-09-29 23:49:27,472 - epoch:4, training loss:693.7118 validation loss:14.3661
2024-09-29 23:49:30,997 - epoch:5, training loss:685.9930 validation loss:15.2987
2024-09-29 23:49:33,910 - epoch:6, training loss:686.1578 validation loss:14.5198
2024-09-29 23:49:36,749 - epoch:7, training loss:690.3969 validation loss:14.2722
2024-09-29 23:49:40,810 - epoch:8, training loss:676.4234 validation loss:14.2873
2024-09-29 23:49:45,078 - epoch:9, training loss:673.8283 validation loss:14.5238
2024-09-29 23:49:48,590 - epoch:10, training loss:682.5689 validation loss:14.2744
2024-09-29 23:49:51,749 - epoch:11, training loss:671.7021 validation loss:14.2483
2024-09-29 23:49:55,586 - epoch:12, training loss:669.2340 validation loss:14.6260
2024-09-29 23:49:58,837 - epoch:13, training loss:673.8040 validation loss:14.4620
2024-09-29 23:50:01,757 - epoch:14, training loss:670.7144 validation loss:14.3160
2024-09-29 23:50:05,107 - epoch:15, training loss:658.7113 validation loss:14.2359
2024-09-29 23:50:08,852 - epoch:16, training loss:655.8990 validation loss:14.3614
2024-09-29 23:50:12,524 - epoch:17, training loss:657.9797 validation loss:14.5176
2024-09-29 23:50:15,902 - epoch:18, training loss:653.4337 validation loss:14.5420
2024-09-29 23:50:19,560 - epoch:19, training loss:654.2709 validation loss:14.1715
2024-09-29 23:50:23,022 - epoch:20, training loss:651.4877 validation loss:14.4739
2024-09-29 23:50:26,064 - epoch:21, training loss:652.0061 validation loss:14.4679
2024-09-29 23:50:28,882 - epoch:22, training loss:647.1244 validation loss:14.2275
2024-09-29 23:50:31,810 - epoch:23, training loss:645.4902 validation loss:14.2666
2024-09-29 23:50:34,253 - epoch:24, training loss:645.8431 validation loss:14.5112
2024-09-29 23:50:36,879 - epoch:25, training loss:650.5973 validation loss:14.5827
2024-09-29 23:50:38,598 - [*] loss:864.7192
2024-09-29 23:50:38,646 - [*] year 2016, testing
2024-09-29 23:50:39,045 - T:3	MAE	13.3850	RMSE	23.0023	MAPE	17.0999
2024-09-29 23:50:39,780 - T:6	MAE	14.5635	RMSE	25.3245	MAPE	18.2234
2024-09-29 23:50:42,199 - T:12	MAE	17.1333	RMSE	29.6692	MAPE	21.3290
2024-09-29 23:50:42,200 - T:Avg	MAE	14.7967	RMSE	25.5744	MAPE	18.6082
2024-09-29 23:50:42,201 - Finished optimization, total time:45.76 s, best model:log/PEMS-Few/oneline_st_nn_pems-few-43/2016/14.1715.pkl
2024-09-29 23:50:42,228 - [*] Year 2017 load from data/PEMS-Few/FastData/2017.npz
2024-09-29 23:50:42,239 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2016/14.1715.pkl
2024-09-29 23:50:42,596 - number of increase nodes:20, nodes after 2 hop:torch.Size([60]), total nodes this year 871
2024-09-29 23:50:43,135 - [*] Year 2017 Dataset load!
2024-09-29 23:50:43,135 - [*] load from log/PEMS-Few/oneline_st_nn_pems-few-43/2016/14.1715.pkl
2024-09-29 23:50:43,300 - Total Parameters: 3308
2024-09-29 23:50:43,300 - Trainable Parameters: 3308
2024-09-29 23:50:43,300 - [*] Year 2017 Training start
2024-09-29 23:50:44,247 - node number torch.Size([7680, 12])
2024-09-29 23:50:45,539 - epoch:0, training loss:320.4035 validation loss:10.5018
2024-09-29 23:50:49,101 - epoch:1, training loss:237.3764 validation loss:10.3647
2024-09-29 23:50:52,673 - epoch:2, training loss:211.2079 validation loss:9.6864
2024-09-29 23:50:54,772 - epoch:3, training loss:206.3622 validation loss:9.8561
2024-09-29 23:50:58,458 - epoch:4, training loss:201.9767 validation loss:9.8994
2024-09-29 23:51:01,689 - epoch:5, training loss:199.6694 validation loss:10.0009
2024-09-29 23:51:03,905 - epoch:6, training loss:197.1453 validation loss:10.1870
2024-09-29 23:51:07,042 - epoch:7, training loss:197.2746 validation loss:9.6643
2024-09-29 23:51:10,310 - epoch:8, training loss:198.1575 validation loss:9.6078
2024-09-29 23:51:13,106 - epoch:9, training loss:195.4366 validation loss:9.8173
2024-09-29 23:51:16,012 - epoch:10, training loss:193.5898 validation loss:9.8863
2024-09-29 23:51:19,774 - epoch:11, training loss:192.4621 validation loss:9.7119
2024-09-29 23:51:23,195 - epoch:12, training loss:192.1458 validation loss:10.0748
2024-09-29 23:51:25,736 - epoch:13, training loss:193.8771 validation loss:9.6088
2024-09-29 23:51:28,199 - epoch:14, training loss:191.8391 validation loss:9.7427
2024-09-29 23:51:29,856 - [*] loss:1870.0566
2024-09-29 23:51:29,887 - [*] year 2017, testing
2024-09-29 23:51:30,220 - T:3	MAE	16.8476	RMSE	28.0006	MAPE	19.1208
2024-09-29 23:51:30,906 - T:6	MAE	19.3790	RMSE	32.7382	MAPE	20.6129
2024-09-29 23:51:33,048 - T:12	MAE	25.1308	RMSE	43.7412	MAPE	24.4767
2024-09-29 23:51:33,049 - T:Avg	MAE	19.9703	RMSE	33.9192	MAPE	21.0838
2024-09-29 23:51:33,050 - Finished optimization, total time:23.51 s, best model:log/PEMS-Few/oneline_st_nn_pems-few-43/2017/9.6078.pkl
2024-09-29 23:51:33,060 - 


2024-09-29 23:51:33,061 - 3   	 MAE	     13.51	     14.09	     13.53	     13.96	     15.89	     13.39	     16.85		   14.46
2024-09-29 23:51:33,061 - 3   	RMSE	     20.55	     21.88	     21.58	     22.31	     25.71	     23.00	     28.00		   23.29
2024-09-29 23:51:33,061 - 3   	MAPE	     17.61	     22.45	     17.72	     18.19	     19.06	     17.10	     19.12		   18.75
2024-09-29 23:51:33,061 - 6   	 MAE	     14.46	     14.99	     14.59	     15.05	     17.74	     14.56	     19.38		   15.82
2024-09-29 23:51:33,061 - 6   	RMSE	     22.22	     23.53	     23.60	     24.39	     29.17	     25.32	     32.74		   25.85
2024-09-29 23:51:33,061 - 6   	MAPE	     18.71	     23.39	     18.79	     19.13	     20.44	     18.22	     20.61		   19.90
2024-09-29 23:51:33,061 - 12  	 MAE	     16.47	     17.33	     17.05	     17.54	     21.91	     17.13	     25.13		   18.94
2024-09-29 23:51:33,061 - 12  	RMSE	     25.59	     27.59	     27.80	     28.75	     36.77	     29.67	     43.74		   31.42
2024-09-29 23:51:33,061 - 12  	MAPE	     21.30	     26.18	     21.51	     21.56	     23.55	     21.33	     24.48		   22.84
2024-09-29 23:51:33,061 - Avg 	 MAE	     14.63	     15.28	     14.83	     15.28	     18.14	     14.80	     19.97		   16.13
2024-09-29 23:51:33,062 - Avg 	RMSE	     22.46	     23.98	     23.92	     24.73	     29.87	     25.57	     33.92		   26.35
2024-09-29 23:51:33,062 - Avg 	MAPE	     18.98	     23.95	     19.08	     19.39	     20.72	     18.61	     21.08		   20.26
2024-09-29 23:51:33,062 - year	2011	total_time	  296.1973	average_time	    5.8078	epoch	51
2024-09-29 23:51:33,062 - year	2012	total_time	  201.4107	average_time	    6.9452	epoch	29
2024-09-29 23:51:33,062 - year	2013	total_time	  110.9695	average_time	    4.6237	epoch	24
2024-09-29 23:51:33,062 - year	2014	total_time	   60.2357	average_time	    5.0197	epoch	12
2024-09-29 23:51:33,062 - year	2015	total_time	   53.5364	average_time	    3.1492	epoch	17
2024-09-29 23:51:33,062 - year	2016	total_time	   45.7607	average_time	    1.7600	epoch	26
2024-09-29 23:51:33,062 - year	2017	total_time	   23.5118	average_time	    1.5675	epoch	15
2024-09-29 23:51:33,062 - total time: 791.6222
